{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Genki Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Sources and Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# NOTE: this isn't required when the library has been installed from PyPI\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first building block of Genki Signals is the `SignalSource`\n",
    "\n",
    "SignalSource is a callable that returns the current value of that Signal. It can be a function or a class with a `__call__` method. One example is the `MouseSource` that gives the current position of the pointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genki_signals.sources import MouseSource, KeyboardSource\n",
    "\n",
    "source = MouseSource()\n",
    "keyboard_source = KeyboardSource(['m','e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously we want to gather multiple samples of this signal. For that we need a `Sampler`.\n",
    "\n",
    "A Sampler simply samples one or many SignalSources at a given _sample rate_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genki_signals.sources import Sampler\n",
    "\n",
    "# sources is a dictionary mapping names to signal esources\n",
    "sampler = Sampler(sources = {\"mouse\": source, \"keyboard\" : keyboard_source}, sample_rate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the sampler samples the mouse position at a rate of 100 samples / second (hz) (This happens in a separate thread so the cell still returns and the main thread is unblocked.)\n",
    "\n",
    "Signal Sources and Samplers are the way to get raw data into Genki Signals, usually from some external source, like a web API or an external device. Sometimes these will be combined into a single class, e.g. a microphone that samples audio data at a specific sample rate which we have no control over, but more on that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Functions and Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to do some processing on the samples from our sampler. \n",
    "\n",
    "This is where SignalFunctions come in. SignalFunctions are functions that take in one or more signals and return another signal.\n",
    "\n",
    "There is a collection of SignalFunctions available in `genki_signals.functions` and they all have a similar structure, to create one you need to specify some _input names_ and also a _name_ for the output signal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genki_signals.functions as f\n",
    "\n",
    "# diff differentiates the \"mouse\" signals with regard to the \"timestamp\" and returns the signal \"mouse_vel\"\n",
    "# the \"mouse\" signal is the one we created earlier and \"timestamp\" is created automatically by the sampler\n",
    "\n",
    "diff = f.Differentiate(input_a=\"mouse\", input_b=\"timestamp\", name=\"mouse_vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to introduce one more concept to connect all of this together: the System.\n",
    "\n",
    "System takes in a Sampler/SignalSource and a list of SignalFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genki_signals.system import System\n",
    "\n",
    "system = System(sampler, [diff])\n",
    "\n",
    "system.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `functions` module contains a library of functions to do signal arithmetic, digital signal processing, e.g. filtering, geometric calculations (useful for IMU sensors), create basic waveforms, run real time inference with machine learningh models, and more. We will dive into these in depth later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the minimal setup we need. With a system, we can add signal functions to do all kinds of processing, and we can do data recording to start building a dataset. However, probably the most useful part of Genki Signals is the real-time visualization. For that we need a `Frontend`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genki_signals.buffers import DataBuffer\n",
    "\n",
    "buffer = DataBuffer()\n",
    "\n",
    "system.register_data_feed(id(buffer), lambda d: buffer.extend(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBuffer(max_size=None, data=timestamp: (39,)\n",
       "mouse: (2, 39)\n",
       "keyboard_pressing_a: (39,)\n",
       "keyboard_pressing_b: (39,)\n",
       "mouse_vel: (2, 39))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from genki_signals.frontends import WidgetFrontend\n",
    "from genki_widgets import Trace\n",
    "\n",
    "trace = Trace(('mouse', 0), ('mouse', 1), x_axis_visible = False, y_axis_visible = False, y_axis_flipped = True, n_visible_points = 200)\n",
    "\n",
    "\n",
    "\n",
    "system.register_data_feed(id(trace), lambda d: trace.update(d.as_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5f6f13a1104e67a8e9ed232dd3a470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Trace(data={'timestamp': [[1684609954.676846, 1684609954.6928887, 1684609954.7088563]], 'mouse': [[424, 424, 4â€¦"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.start_recording('e4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.stop_recording()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `WidgetFrontend` is a front end specifically designed for jupyter notebooks. In the above cell we create two `Line` widgets and combine them into a `dashboard` object that is then rendered in a notebook. A Genki Signals frontend can also be a separate web server or any sort of GUI to visualize and interact with the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `dashboard` object displays the data in real time. The last basic feature we will introduce is recording. To start recording data, we can simply call `system.start_recording()` and give it a filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.start_recording('session_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name `session_1` will be the name of a folder. We'll see its contents in a bit.\n",
    "\n",
    "We are now recording data, try moving the mouse around a bit and run the next cell to stop recording (and stop everything):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.stop_recording()\n",
    "system.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system created the folder `session_1`, let's see what it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls session_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`raw_data.pickle` contains the recorded data, whereas `metadata.json` contains various information about this recording session. Instead of reading these files directly we can load them in a `Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = 'e4'\n",
    "session = Session.from_filename(file)\n",
    "cut = session.raw_data['keyboard_pressing_'+file[0]]\n",
    "count = 0\n",
    "start_end = dict()\n",
    "for i in range(1,len(cut)):\n",
    "    count += 1\n",
    "    if(cut[i-1]==0 and cut[i]==1): \n",
    "        start = count\n",
    "    if(cut[i-1]==1 and cut[i]==0): \n",
    "        end = count\n",
    "        start_end[start] = end\n",
    "        start = 0\n",
    "        end = 0\n",
    "        \n",
    "mouse_position_data = session.raw_data['mouse']\n",
    "for start in start_end:\n",
    "    plt.axis('off')\n",
    "    plt.plot(mouse_position_data[0, start:start_end[start]], -mouse_position_data[1, start:start_end[start]])\n",
    "    name = filename[0]+str(time.time())+\".png\"\n",
    "    filepath = os.path.join('C://Users//mitae//Documents//genki-signals//examples//test', name)\n",
    "    if not os.path.exists('C://Users//mitae//Documents//genki-signals//examples//test'):\n",
    "        os.makedirs('C://Users//mitae//Documents//genki-signals//examples//test')\n",
    "    plt.savefig(filepath, bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No raw data file found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m sessions:\n\u001b[0;32m     12\u001b[0m     session \u001b[38;5;241m=\u001b[39m Session\u001b[38;5;241m.\u001b[39mfrom_filename(filename)\n\u001b[1;32m---> 13\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_data\u001b[49m\n\u001b[0;32m     14\u001b[0m     session_time[filename] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(session\u001b[38;5;241m.\u001b[39mraw_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\genki_signals\\session.py:158\u001b[0m, in \u001b[0;36mSession.raw_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\genki_signals\\session.py:98\u001b[0m, in \u001b[0;36mSession._load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatafile_extension\u001b[49m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m FILE:\n\u001b[0;32m    100\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(FILE)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\genki_signals\\session.py:132\u001b[0m, in \u001b[0;36mSession.datafile_extension\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdatafile_extension\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datafile_extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_raw_data_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datafile_extension\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\genki_signals\\session.py:117\u001b[0m, in \u001b[0;36mSession._find_raw_data_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m found \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_data.*\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(found) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo raw data file found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(found) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple raw data files found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No raw data file found"
     ]
    }
   ],
   "source": [
    "from genki_signals.session import Session\n",
    "\n",
    "import os\n",
    "\n",
    "# Get all sessions folders\n",
    "ban = ['.ipynb','.png']\n",
    "sessions = [f for f in os.listdir('C:\\\\Users\\\\mitae\\\\Documents\\\\genki-signals\\\\examples') if ban[0] not in f and ban[1] not in f]\n",
    "\n",
    "# Check length of each session, create dictionary\n",
    "session_time = dict()\n",
    "for filename in sessions:\n",
    "    session = Session.from_filename(filename)\n",
    "    session.raw_data\n",
    "    session_time[filename] = len(session.raw_data['timestamp'])\n",
    "\n",
    "#print(session_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time, os\n",
    "\n",
    "mouse_position_data = session.raw_data['mouse']\n",
    "\n",
    "\n",
    "def makeimages(session_time):\n",
    "    '''returns a collection of png files for graphs created during the session at 100ms intervals inside datasets folder'''\n",
    "    for filename in session_time:\n",
    "        # Go through the keyboard_pressing_<key>, start:end = 0 to 1: 1 to 0\n",
    "        \n",
    "        for i in range(0,session_time[filename],100):\n",
    "            plt.axis('off')\n",
    "            plt.plot(mouse_position_data[0, i:i+100], -mouse_position_data[1, i:i+100])\n",
    "            name = filename[0]+str(time.time())+\".png\"\n",
    "            filepath = os.path.join('C://Users//mitae//Documents//genki-signals//examples//datasets', name)\n",
    "            if not os.path.exists('C://Users//mitae//Documents//genki-signals//examples//datasets'):\n",
    "                os.makedirs('C://Users//mitae//Documents//genki-signals//examples//datasets')\n",
    "            plt.savefig(filepath, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "            \n",
    "makeimages(session_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a dataset of mouse positions! \n",
    "\n",
    "Note that we don't actually store the differentiated signal `mouse_vel`, we only store the raw data which is treated as a source of truth. The `SignalFunction`s are serialized and stored in `metadata.json`. All `SignalFunction`s are deterministic so they can be recomputed at will. This means that the signal functions (and their parameters, if any) can be used as hyperparameters in ML training. For example, if you want to use a low-pass filter on some signal, the exact cutoff frequency of the filter can be treated as a hyperparameter.\n",
    "\n",
    "The `metadata.json` can also contain arbitrary information about the particular session. This can also be useful in a machine learning setting if you wish to, for example, make sure the data is split into train and test based on _individuals_, so that no individual who appears in the test set has any data in the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we have introduced a lot of concepts:\n",
    "\n",
    "* A `SignalSource` is some way to get an external signal\n",
    "* A `Sampler` samples values from a `SignalSource` at a given rate\n",
    "* A `SignalFunction` is some function to process signals\n",
    "* A `SignalSystem` ties all of the above together and records data\n",
    "* A `Session` is some data that was recorded in a single recording session\n",
    "* A `Frontend` is a way to visualize what is going on in a system and to interact with it\n",
    "\n",
    "We have only scratched the surface of these components. This should be enough to get started but in the following notebooks we will cover each of these in more depth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d1ca8cbf69155084332556ae3352aa9e7bf4a96dd6bb5cc51f4289812d36157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
