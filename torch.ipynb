{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "classes = tuple(x for x in \"_\" + string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data\\EMNIST\\raw\\gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\EMNIST\\raw\\gzip.zip to ./data\\EMNIST\\raw\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.EMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform, split=\"letters\")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.EMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform, split=\"letters\")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v    , tensor([22,  8,  9, 18])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.rot90(npimg,3)\n",
    "    npimg = np.fliplr(npimg)\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(images[0][0])\n",
    "# print labels\n",
    "print(f'{classes[labels[0]]:5s}, {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2, 11, 19, 14])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 27)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 27]           2,295\n",
      "================================================================\n",
      "Total params: 45,871\n",
      "Trainable params: 45,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary \n",
    "\n",
    "torchsummary.summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.351\n",
      "[1,  4000] loss: 0.607\n",
      "[1,  6000] loss: 0.511\n",
      "[1,  8000] loss: 0.485\n",
      "[1, 10000] loss: 0.424\n",
      "[1, 12000] loss: 0.388\n",
      "[1, 14000] loss: 0.371\n",
      "[1, 16000] loss: 0.349\n",
      "[1, 18000] loss: 0.350\n",
      "[1, 20000] loss: 0.342\n",
      "[1, 22000] loss: 0.327\n",
      "[1, 24000] loss: 0.315\n",
      "[1, 26000] loss: 0.308\n",
      "[1, 28000] loss: 0.297\n",
      "[1, 30000] loss: 0.304\n",
      "[2,  2000] loss: 0.276\n",
      "[2,  4000] loss: 0.291\n",
      "[2,  6000] loss: 0.285\n",
      "[2,  8000] loss: 0.274\n",
      "[2, 10000] loss: 0.254\n",
      "[2, 12000] loss: 0.267\n",
      "[2, 14000] loss: 0.262\n",
      "[2, 16000] loss: 0.270\n",
      "[2, 18000] loss: 0.279\n",
      "[2, 20000] loss: 0.256\n",
      "[2, 22000] loss: 0.272\n",
      "[2, 24000] loss: 0.261\n",
      "[2, 26000] loss: 0.274\n",
      "[2, 28000] loss: 0.261\n",
      "[2, 30000] loss: 0.271\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  b     b     b     b    \n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  b     k     s     n    \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m images, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m      7\u001b[0m \u001b[39m# calculate outputs by running images through the network\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m outputs \u001b[39m=\u001b[39m net(images)\n\u001b[0;32m      9\u001b[0m \u001b[39m# the class with the highest energy is what we choose as prediction\u001b[39;00m\n\u001b[0;32m     10\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)))\n\u001b[1;32m---> 17\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)))\n\u001b[0;32m     18\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m) \u001b[39m# flatten all dimensions except batch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: _     is 0.0 %\n",
      "Accuracy for class: a     is 92.9 %\n",
      "Accuracy for class: b     is 95.4 %\n",
      "Accuracy for class: c     is 96.6 %\n",
      "Accuracy for class: d     is 91.5 %\n",
      "Accuracy for class: e     is 93.9 %\n",
      "Accuracy for class: f     is 95.9 %\n",
      "Accuracy for class: g     is 76.0 %\n",
      "Accuracy for class: h     is 96.5 %\n",
      "Accuracy for class: i     is 64.1 %\n",
      "Accuracy for class: j     is 92.4 %\n",
      "Accuracy for class: k     is 95.6 %\n",
      "Accuracy for class: l     is 82.0 %\n",
      "Accuracy for class: m     is 97.9 %\n",
      "Accuracy for class: n     is 86.1 %\n",
      "Accuracy for class: o     is 95.1 %\n",
      "Accuracy for class: p     is 96.0 %\n",
      "Accuracy for class: q     is 82.1 %\n",
      "Accuracy for class: r     is 92.6 %\n",
      "Accuracy for class: s     is 96.8 %\n",
      "Accuracy for class: t     is 92.6 %\n",
      "Accuracy for class: u     is 92.0 %\n",
      "Accuracy for class: v     is 90.5 %\n",
      "Accuracy for class: w     is 94.9 %\n",
      "Accuracy for class: x     is 95.2 %\n",
      "Accuracy for class: y     is 79.0 %\n",
      "Accuracy for class: z     is 97.4 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / (total_pred[classname]+ 0.00000000000001)\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor([[6.3075e-08, 1.6089e-01, 1.7576e-01, 3.4269e-03, 4.5166e-03, 2.9940e-02,\n",
      "         2.1659e-02, 6.2856e-02, 8.5832e-03, 2.7537e-04, 1.9538e-03, 1.7174e-02,\n",
      "         3.4450e-03, 9.2474e-03, 1.0047e-02, 4.5950e-03, 5.8402e-02, 1.8500e-01,\n",
      "         2.0080e-01, 1.9804e-02, 1.3587e-03, 2.3158e-03, 1.7115e-04, 1.8428e-03,\n",
      "         4.4580e-03, 1.0385e-03, 1.0443e-02]], grad_fn=<SoftmaxBackward0>)\n",
      "r    \n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "image = Image.open(\"examples/demo/e.png\")\n",
    "image = image.convert(\"1\")\n",
    "x = TF.to_tensor(image).squeeze()\n",
    "x = x.numpy()\n",
    "print(x.shape)\n",
    "x = np.fliplr(x)\n",
    "x = np.rot90(x)\n",
    "\n",
    "x = torch.from_numpy(x.copy())\n",
    "imshow(x)\n",
    "x = x.unsqueeze(0)\n",
    "print(x.shape)\n",
    "\n",
    "output = net(x.unsqueeze(0))\n",
    "output = torch.softmax(output, 1)\n",
    "print(output)\n",
    "output = torch.argmax(output)\n",
    "print(f'{classes[output]:5s}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hakkathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
