{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
<<<<<<< HEAD
    "classes = tuple(x for x in \"_\" + string.ascii_letters)"
=======
    "classes = tuple(x for x in \"_\" + string.ascii_uppercase)"
>>>>>>> a5277fd2ff420916e116461b05fbdcecab05187e
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data\\EMNIST\\raw\\gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14.8%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(\n\u001b[0;32m      2\u001b[0m     [transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[0;32m      3\u001b[0m      transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.5\u001b[39m,), (\u001b[39m0.5\u001b[39m,))])\n\u001b[0;32m      5\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m----> 7\u001b[0m trainset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mEMNIST(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data\u001b[39;49m\u001b[39m'\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      8\u001b[0m                                         download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49mtransform, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mletters\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m trainloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(trainset, batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     10\u001b[0m                                           shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m testset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mEMNIST(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m                                        download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, transform\u001b[39m=\u001b[39mtransform, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mletters\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\mnist.py:297\u001b[0m, in \u001b[0;36mEMNIST.__init__\u001b[1;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_file(split)\n\u001b[0;32m    296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_test_file(split)\n\u001b[1;32m--> 297\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_split_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit]\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[0;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\mnist.py:334\u001b[0m, in \u001b[0;36mEMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    332\u001b[0m os\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_folder, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 334\u001b[0m download_and_extract_archive(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, download_root\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_folder, md5\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmd5)\n\u001b[0;32m    335\u001b[0m gzip_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_folder, \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    336\u001b[0m \u001b[39mfor\u001b[39;00m gzip_file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(gzip_folder):\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:\n\u001b[0;32m    432\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(url)\n\u001b[1;32m--> 434\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[0;32m    436\u001b[0m archive \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    437\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m{\u001b[39;00marchive\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mextract_root\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\utils.py:144\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m url \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m fpath)\n\u001b[1;32m--> 144\u001b[0m     _urlretrieve(url, fpath)\n\u001b[0;32m    145\u001b[0m \u001b[39mexcept\u001b[39;00m (urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mURLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m url[:\u001b[39m5\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\utils.py:48\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_urlretrieve\u001b[39m(url: \u001b[39mstr\u001b[39m, filename: \u001b[39mstr\u001b[39m, chunk_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m32\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[39mwith\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: USER_AGENT})) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m---> 48\u001b[0m         _save_response_content(\u001b[39miter\u001b[39;49m(\u001b[39mlambda\u001b[39;49;00m: response\u001b[39m.\u001b[39;49mread(chunk_size), \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m), filename, length\u001b[39m=\u001b[39;49mresponse\u001b[39m.\u001b[39;49mlength)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\utils.py:37\u001b[0m, in \u001b[0;36m_save_response_content\u001b[1;34m(content, destination, length)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_save_response_content\u001b[39m(\n\u001b[0;32m     32\u001b[0m     content: Iterator[\u001b[39mbytes\u001b[39m],\n\u001b[0;32m     33\u001b[0m     destination: \u001b[39mstr\u001b[39m,\n\u001b[0;32m     34\u001b[0m     length: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(destination, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fh, tqdm(total\u001b[39m=\u001b[39mlength) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m---> 37\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m content:\n\u001b[0;32m     38\u001b[0m             \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m     39\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[0;32m     40\u001b[0m                 \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torchvision\\datasets\\utils.py:48\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_urlretrieve\u001b[39m(url: \u001b[39mstr\u001b[39m, filename: \u001b[39mstr\u001b[39m, chunk_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m32\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[39mwith\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: USER_AGENT})) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m---> 48\u001b[0m         _save_response_content(\u001b[39miter\u001b[39m(\u001b[39mlambda\u001b[39;00m: response\u001b[39m.\u001b[39;49mread(chunk_size), \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m), filename, length\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mlength)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    464\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
=======
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
>>>>>>> a5277fd2ff420916e116461b05fbdcecab05187e
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.EMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform, split=\"letters\")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.EMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform, split=\"letters\")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     16\u001b[0m \u001b[39m# get some random training images\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(trainloader)\n\u001b[0;32m     18\u001b[0m images, labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dataiter)\n\u001b[0;32m     20\u001b[0m \u001b[39m# show images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
=======
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X    , tensor([24, 11,  1, 16])\n"
>>>>>>> a5277fd2ff420916e116461b05fbdcecab05187e
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.rot90(npimg,3)\n",
    "    npimg = np.fliplr(npimg)\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(images[0][0])\n",
    "# print labels\n",
    "print(f'{classes[labels[0]]:5s}, {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 24,  7,  3])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 27)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 27]           2,295\n",
      "================================================================\n",
      "Total params: 45,871\n",
      "Trainable params: 45,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary \n",
    "\n",
    "torchsummary.summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 119,
>>>>>>> a5277fd2ff420916e116461b05fbdcecab05187e
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#criterion = nn.CrossEntropyLoss()\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(net\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.277\n",
      "[1,  4000] loss: 0.617\n",
      "[1,  6000] loss: 0.515\n",
      "[1,  8000] loss: 0.454\n",
      "[1, 10000] loss: 0.415\n",
      "[1, 12000] loss: 0.383\n",
      "[1, 14000] loss: 0.376\n",
      "[1, 16000] loss: 0.341\n",
      "[1, 18000] loss: 0.349\n",
      "[1, 20000] loss: 0.324\n",
      "[1, 22000] loss: 0.354\n",
      "[1, 24000] loss: 0.322\n",
      "[1, 26000] loss: 0.311\n",
      "[1, 28000] loss: 0.305\n",
      "[1, 30000] loss: 0.295\n",
      "[2,  2000] loss: 0.276\n",
      "[2,  4000] loss: 0.269\n",
      "[2,  6000] loss: 0.277\n",
      "[2,  8000] loss: 0.273\n",
      "[2, 10000] loss: 0.292\n",
      "[2, 12000] loss: 0.279\n",
      "[2, 14000] loss: 0.268\n",
      "[2, 16000] loss: 0.271\n",
      "[2, 18000] loss: 0.277\n",
      "[2, 20000] loss: 0.278\n",
      "[2, 22000] loss: 0.287\n",
      "[2, 24000] loss: 0.253\n",
      "[2, 26000] loss: 0.263\n",
      "[2, 28000] loss: 0.260\n",
      "[2, 30000] loss: 0.265\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  A     A     A     A    \n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  U     A     A     A    \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 90 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: _     is 0.0 %\n",
      "Accuracy for class: A     is 89.8 %\n",
      "Accuracy for class: B     is 96.0 %\n",
      "Accuracy for class: C     is 97.2 %\n",
      "Accuracy for class: D     is 93.1 %\n",
      "Accuracy for class: E     is 91.8 %\n",
      "Accuracy for class: F     is 94.8 %\n",
      "Accuracy for class: G     is 73.0 %\n",
      "Accuracy for class: H     is 90.8 %\n",
      "Accuracy for class: I     is 46.2 %\n",
      "Accuracy for class: J     is 90.4 %\n",
      "Accuracy for class: K     is 94.6 %\n",
      "Accuracy for class: L     is 86.2 %\n",
      "Accuracy for class: M     is 98.8 %\n",
      "Accuracy for class: N     is 91.1 %\n",
      "Accuracy for class: O     is 96.9 %\n",
      "Accuracy for class: P     is 97.0 %\n",
      "Accuracy for class: Q     is 85.1 %\n",
      "Accuracy for class: R     is 93.0 %\n",
      "Accuracy for class: S     is 96.0 %\n",
      "Accuracy for class: T     is 94.1 %\n",
      "Accuracy for class: U     is 87.0 %\n",
      "Accuracy for class: V     is 90.1 %\n",
      "Accuracy for class: W     is 95.9 %\n",
      "Accuracy for class: X     is 94.5 %\n",
      "Accuracy for class: Y     is 96.2 %\n",
      "Accuracy for class: Z     is 96.8 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / (total_pred[classname]+ 0.00000000000001)\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m word \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m L:\n\u001b[1;32m---> 10\u001b[0m     Image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39mexamples/demo/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mfile)\n\u001b[0;32m     11\u001b[0m     Image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     x \u001b[39m=\u001b[39m TF\u001b[39m.\u001b[39mto_tensor(Image)\u001b[39m.\u001b[39msqueeze()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir = os.listdir(\"C://Users//Lenovo//OneDrive - Háskóli Íslands//Hakkathon//hakkathon//examples//demo\")\n",
    "L = list()\n",
    "for i in dir:\n",
    "    L.append(i)\n",
    "\n",
    "word = \"\"\n",
    "for file in L:\n",
    "    Image = Image.open(\"examples/demo/\"+file)\n",
    "    Image = Image.convert(\"1\")\n",
    "    x = TF.to_tensor(Image).squeeze()\n",
    "    x = x.numpy()\n",
    "    x = np.fliplr(x)\n",
    "    x = np.rot90(x)\n",
    "    x = torch.from_numpy(x.copy())\n",
    "    imshow(x)\n",
    "    x = x.unsqueeze(0)\n",
    "    output = net(x.unsqueeze(0))\n",
    "    output = torch.softmax(output, 1)\n",
    "    output = torch.argmax(output)\n",
    "    word += classes[output]\n",
    "\n",
    "\n",
    "print(word)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#output = net(x.unsqueeze(0))\n",
    "#output = torch.softmax(output, 1)\n",
    "#print(output)\n",
    "#output = torch.argmax(output)\n",
    "#print(f'{classes[output]:5s}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x16 and 256x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net2(torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m,\u001b[39m28\u001b[39;49m,\u001b[39m28\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[0;32m     18\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m) \u001b[39m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[0;32m     20\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[0;32m     21\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x16 and 256x120)"
     ]
    }
   ],
   "source": [
    "net2(torch.randn(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
=======
   "execution_count": 156,
>>>>>>> a5277fd2ff420916e116461b05fbdcecab05187e
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 27]           2,295\n",
      "================================================================\n",
      "Total params: 45,871\n",
      "Trainable params: 45,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
=======
      "MAPPA\n",
      "GORMUR\n",
      "HELLU\n"
>>>>>>> a5277fd2ff420916e116461b05fbdcecab05187e
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "torchsummary.summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 27]           2,295\n",
      "================================================================\n",
      "Total params: 45,871\n",
      "Trainable params: 45,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(net2, (1, 28, 28))"
=======
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "L = ['bigM', 'bigA','bigP','bigP','bigA']\n",
    "M = ['bigG', 'bigO','bigR','bigM','bigU','bigR']\n",
    "N = ['bigH', 'bigE','bigL','bigL','bigU']\n",
    "\n",
    "def read_from_image(L):\n",
    "    word = \"\"\n",
    "    for i in range(len(L)):\n",
    "        image = Image.open(\"examples/demo/\"+str(L[i])+\".png\")\n",
    "        image = image.convert(\"1\")\n",
    "        x = TF.to_tensor(image).squeeze()\n",
    "        x = x.numpy()\n",
    "        #print(x.shape)\n",
    "        x = np.fliplr(x)\n",
    "        x = np.rot90(x)\n",
    "        x = torch.from_numpy(x.copy())\n",
    "        #imshow(x)\n",
    "        x = x.unsqueeze(0)\n",
    "        #print(x.shape)\n",
    "        output = net(x.unsqueeze(0))\n",
    "        output = torch.softmax(output, 1)\n",
    "        #print(output)\n",
    "        output = torch.argmax(output)\n",
    "        #print(f'{classes[output]:5s}') \n",
    "        word+=classes[output]\n",
    "    return word\n",
    "\n",
    "\n",
    "wordL = read_from_image(L)\n",
    "wordM = read_from_image(M)\n",
    "wordN = read_from_image(N)\n",
    "print(wordL)\n",
    "print(wordM)\n",
    "print(wordN)\n"
>>>>>>> a5277fd2ff420916e116461b05fbdcecab05187e
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rétt\n",
      "Rétt\n",
      "Rétt\n"
     ]
    }
   ],
   "source": [
    "from islenska import Bin\n",
    "\n",
    "def er_þetta_orð(wordL):\n",
    "    b = Bin()\n",
    "    x = len(b.lookup(wordL)[1])\n",
    "    if(x==0): return \"Rangt, prófa aftur\"\n",
    "    else: return \"Rétt\"\n",
    "\n",
    "print(er_þetta_orð(wordL))\n",
    "print(er_þetta_orð(wordM))\n",
    "print(er_þetta_orð(wordN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
