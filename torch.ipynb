{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "classes = tuple(x for x in \"_\" + string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.EMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform, split=\"letters\")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.EMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform, split=\"letters\")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N    , tensor([14, 11, 12, 24])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.rot90(npimg,3)\n",
    "    npimg = np.fliplr(npimg)\n",
    "    plt.imshow(npimg, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(images[0][0])\n",
    "# print labels\n",
    "print(f'{classes[labels[0]]:5s}, {labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 20, 26, 13])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 27)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          30,840\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 27]           2,295\n",
      "================================================================\n",
      "Total params: 45,871\n",
      "Trainable params: 45,871\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary \n",
    "\n",
    "torchsummary.summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.282\n",
      "[1,  4000] loss: 0.581\n",
      "[1,  6000] loss: 0.470\n",
      "[1,  8000] loss: 0.414\n",
      "[1, 10000] loss: 0.387\n",
      "[1, 12000] loss: 0.380\n",
      "[1, 14000] loss: 0.364\n",
      "[1, 16000] loss: 0.365\n",
      "[1, 18000] loss: 0.348\n",
      "[1, 20000] loss: 0.327\n",
      "[1, 22000] loss: 0.297\n",
      "[1, 24000] loss: 0.313\n",
      "[1, 26000] loss: 0.312\n",
      "[1, 28000] loss: 0.302\n",
      "[1, 30000] loss: 0.295\n",
      "[2,  2000] loss: 0.272\n",
      "[2,  4000] loss: 0.268\n",
      "[2,  6000] loss: 0.267\n",
      "[2,  8000] loss: 0.266\n",
      "[2, 10000] loss: 0.264\n",
      "[2, 12000] loss: 0.279\n",
      "[2, 14000] loss: 0.269\n",
      "[2, 16000] loss: 0.282\n",
      "[2, 18000] loss: 0.250\n",
      "[2, 20000] loss: 0.267\n",
      "[2, 22000] loss: 0.273\n",
      "[2, 24000] loss: 0.278\n",
      "[2, 26000] loss: 0.257\n",
      "[2, 28000] loss: 0.272\n",
      "[2, 30000] loss: 0.254\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  A     A     A     A    \n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../cifar_net.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m net \u001b[38;5;241m=\u001b[39m Net()\n\u001b[1;32m----> 2\u001b[0m net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hakkathon\\lib\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../cifar_net.pth'"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  A     A     A     A    \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 91 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: _     is 0.0 %\n",
      "Accuracy for class: a     is 0.0 %\n",
      "Accuracy for class: b     is 0.0 %\n",
      "Accuracy for class: c     is 0.0 %\n",
      "Accuracy for class: d     is 0.0 %\n",
      "Accuracy for class: e     is 0.0 %\n",
      "Accuracy for class: f     is 0.0 %\n",
      "Accuracy for class: g     is 0.0 %\n",
      "Accuracy for class: h     is 0.0 %\n",
      "Accuracy for class: i     is 52.8 %\n",
      "Accuracy for class: j     is 0.0 %\n",
      "Accuracy for class: k     is 0.0 %\n",
      "Accuracy for class: l     is 0.0 %\n",
      "Accuracy for class: m     is 0.0 %\n",
      "Accuracy for class: n     is 0.0 %\n",
      "Accuracy for class: o     is 0.0 %\n",
      "Accuracy for class: p     is 0.0 %\n",
      "Accuracy for class: q     is 0.0 %\n",
      "Accuracy for class: r     is 0.0 %\n",
      "Accuracy for class: s     is 0.0 %\n",
      "Accuracy for class: t     is 0.0 %\n",
      "Accuracy for class: u     is 21.5 %\n",
      "Accuracy for class: v     is 0.0 %\n",
      "Accuracy for class: w     is 0.1 %\n",
      "Accuracy for class: x     is 0.0 %\n",
      "Accuracy for class: y     is 0.0 %\n",
      "Accuracy for class: z     is 25.8 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / (total_pred[classname]+ 0.00000000000001)\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor([[4.3230e-08, 2.7793e-02, 7.4175e-02, 1.0562e-02, 2.4810e-03, 1.4795e-01,\n",
      "         2.6105e-02, 2.3833e-02, 2.4469e-03, 1.5836e-04, 4.3064e-05, 4.2055e-02,\n",
      "         3.2276e-03, 5.1722e-04, 1.5045e-02, 2.6499e-04, 4.6863e-02, 3.1587e-02,\n",
      "         5.2222e-01, 1.1913e-03, 5.1079e-04, 1.0860e-03, 2.1947e-04, 2.1627e-03,\n",
      "         6.4273e-03, 2.3789e-04, 1.0842e-02]], grad_fn=<SoftmaxBackward0>)\n",
      "R    \n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "image = Image.open(\"examples/demo/bigR.png\")\n",
    "image = image.convert(\"1\")\n",
    "x = TF.to_tensor(image).squeeze()\n",
    "x = x.numpy()\n",
    "print(x.shape)\n",
    "x = np.fliplr(x)\n",
    "x = np.rot90(x)\n",
    "\n",
    "x = torch.from_numpy(x.copy())\n",
    "imshow(x)\n",
    "x = x.unsqueeze(0)\n",
    "print(x.shape)\n",
    "\n",
    "output = net(x.unsqueeze(0))\n",
    "output = torch.softmax(output, 1)\n",
    "print(output)\n",
    "output = torch.argmax(output)\n",
    "print(f'{classes[output]:5s}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
